{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an implementation of the artistic neural network as described in this [paper](https://arxiv.org/abs/1508.06576). VGG pretrained model weights can be downloaded from [here](http://www.vlfeat.org/matconvnet/models/). Use imagenet-vgg-verydeep-19.mat and imagenet-vgg-verydeep-16.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.io\n",
    "import PIL.Image\n",
    "import cPickle as pickle\n",
    "from IPython.display import clear_output, Image, display\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VGG(object):\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        self.content_layer = None\n",
    "        self.style_layer = None\n",
    "        self.path = path\n",
    "        self.weights = scipy.io.loadmat(self.path)['layers']\n",
    "    \n",
    "    def create_graph(self, input_shape):\n",
    "        \"\"\"\n",
    "        The pretrained model contains the layer name and layer type (i.e. pool, conv etc.)\n",
    "        To access those information, we can do the index access:\n",
    "        vgg_layers[0]      [0]       [0]      [0]      [2]                                    [0]      [0] ## weight\n",
    "        vgg_layers[0]      [0]       [0]      [0]      [2]                                    [0]      [1] ## bias\n",
    "                  always 0 |layer idx|always 0|always 0|0:layer name; 1:layer type; 2: weights|always 0|0:weight; 1:bias\n",
    "        vgg_layers[0][30][0][0][0][0] # to access layer name\n",
    "        vgg_layers[0][30][0][0][1][0] # to access layer type\n",
    "        \n",
    "        Note that the fully connected layers and the softmax are not required for this task, therefore we will skip it. \n",
    "        The fully connected layers have name fc* (It's type is conv though).\n",
    "        \"\"\"\n",
    "        if self.path == None:\n",
    "            raise Exception(\"Run from the child class\")\n",
    "            \n",
    "        vgg_layers = self.weights\n",
    "        num_layers = len(vgg_layers[0])\n",
    "        \n",
    "        graph = {}\n",
    "        layer_names = []\n",
    "        graph[\"input\"] = tf.Variable(np.zeros(input_shape), dtype=tf.float32)\n",
    "        prev = \"input\"\n",
    "        layer_names.append(\"input\")\n",
    "        \n",
    "        for idx in range(num_layers):\n",
    "            \n",
    "            layer_name = vgg_layers[0][idx][0][0][0][0]\n",
    "            layer_type = vgg_layers[0][idx][0][0][1][0]\n",
    "            \n",
    "            if layer_name[:2] == \"fc\":\n",
    "                break                     # stop before adding the first fc layer\n",
    "            \n",
    "            layer_names.append(layer_name)\n",
    "            \n",
    "            if layer_type == \"conv\":\n",
    "                W = vgg_layers[0][idx][0][0][2][0][0]\n",
    "                b = vgg_layers[0][idx][0][0][2][0][1]\n",
    "                W = tf.constant(W)        # we don't want to update the parameters\n",
    "                b = tf.constant(np.reshape(b, (b.size)))\n",
    "                graph[layer_name] = tf.nn.conv2d(graph[prev], filter=W, strides=[1, 1, 1, 1], padding=\"SAME\") + b\n",
    "            elif layer_type == \"relu\":\n",
    "                graph[layer_name] = tf.nn.relu(graph[prev])\n",
    "            elif layer_type == \"pool\":    # according to the paper, average pooling behaves better\n",
    "                graph[layer_name] = tf.nn.avg_pool(graph[prev], ksize=[1, 2, 2, 1], \n",
    "                                                   strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "            else:\n",
    "                raise Exception(\"Unknown layer\")\n",
    "            \n",
    "            prev = layer_name\n",
    "        return graph, layer_names\n",
    "    \n",
    "    def get_layer_names(self):\n",
    "        return self.layer_names\n",
    "    \n",
    "    def get_instance(model_path, force=False):\n",
    "        raise Exception(\"Do not instantiate this class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class VGG19(VGG):\n",
    "    \n",
    "    instance = None\n",
    "    \n",
    "    def __init__(self, model_path):\n",
    "        super(VGG19, self).__init__(model_path)\n",
    "        self.content_layer = \"conv4_2\"\n",
    "#         self.style_layer = {\n",
    "#             \"relu1_1\": 0.2,\n",
    "#             \"relu2_1\": 0.2,\n",
    "#             \"relu3_1\": 0.2,\n",
    "#             \"relu4_1\": 0.2,\n",
    "#             \"relu5_1\": 0.2\n",
    "#         }\n",
    "        self.style_layer = [\n",
    "            (\"relu1_1\", 0.2),\n",
    "            (\"relu2_1\", 0.2),\n",
    "            (\"relu3_1\", 0.2),\n",
    "            (\"relu4_1\", 0.2),\n",
    "            (\"relu5_1\", 0.2)\n",
    "        ]\n",
    "    \n",
    "    def get_instance(model_path, force=False):\n",
    "        \"\"\"\n",
    "        Singleton to avoid load graph on every run\n",
    "        If force is True, then force reload\n",
    "        \"\"\"\n",
    "        if VGG19.instance == None or force:\n",
    "            VGG19.instance = VGG19(model_path)\n",
    "        return VGG19.instance\n",
    "    \n",
    "    get_instance = staticmethod(get_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VGG16(VGG):\n",
    "    \n",
    "    instance = None\n",
    "    \n",
    "    def __init__(self, model_path):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.graph = self.load_model()\n",
    "        self.content_layer = \"relu4_2\"\n",
    "        self.style_layer = {\n",
    "            \"relu1_2\": 0.5,\n",
    "            \"relu2_2\": 1.0,\n",
    "            \"relu3_3\": 1.5,\n",
    "            \"relu4_3\": 1.5,\n",
    "            \"relu5_3\": 4.0\n",
    "        }\n",
    "    \n",
    "    def get_instance(model_path, force=False):\n",
    "        \"\"\"\n",
    "        Singleton to avoid load graph on every run\n",
    "        If force is True, then force reload\n",
    "        \"\"\"\n",
    "        if VGG16.instance == None or force:\n",
    "            VGG16.instance = VGG16(model_path)\n",
    "        return VGG16.instance\n",
    "    \n",
    "    get_instance = staticmethod(get_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VGGFactory(object):\n",
    "    \n",
    "    def factory(name, model_path, force=False):\n",
    "        \"\"\"\n",
    "        The factory to create the corresponding model we will use\n",
    "        Available names include \"VGG16\" and \"VGG19\"\n",
    "        If force is set, then force reload the graph\n",
    "        \"\"\"\n",
    "        if name == \"VGG16\": return VGG16.get_instance(model_path, force)\n",
    "        if name == \"VGG19\": return VGG19.get_instance(model_path, force)\n",
    "    \n",
    "    factory = staticmethod(factory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MagicPen(object):\n",
    "    \"\"\"\n",
    "    The actual class that carries out the image generation\n",
    "    \"\"\"\n",
    "    \n",
    "    # means for RGB channels. I believe it's the training set average for the pretrained model,\n",
    "    # according to this: https://gist.github.com/ksimonyan/211839e770f7b538e2d8. Also various \n",
    "    # sources agree on those values.\n",
    "    IMG_MEAN = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((1,1,1,3))\n",
    "    RANDOM_RATE = 0.4\n",
    "    \n",
    "    def __init__(self, vgg_name, vgg_path, style_path, alpha=None, beta=None, iterations=None):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        print(\"Load graph\")\n",
    "        self.vgg = VGGFactory.factory(vgg_name, vgg_path)\n",
    "        self.style_path = style_path\n",
    "        self.opt_algo = \"lbfgsb\"\n",
    "        print(\"OK\")\n",
    "        \n",
    "    def _generate_base(self, content):\n",
    "        \"\"\"\n",
    "        Add some noise to the content image to get the base image\n",
    "        \"\"\"\n",
    "        random_img = np.random.uniform(-20, 20, content.shape)\n",
    "        return MagicPen.RANDOM_RATE * random_img + content * (1 - MagicPen.RANDOM_RATE)\n",
    "        \n",
    "    def _process_img(self, image):\n",
    "        \"\"\"\n",
    "        Returns the image with 4 dimensions\n",
    "        \"\"\"\n",
    "        image = np.float32(image)\n",
    "#         image = np.reshape(image, ((1,) + image.shape))\n",
    "        image = image[np.newaxis,:,:,:]\n",
    "        image -= MagicPen.IMG_MEAN\n",
    "#         image = image[:, :, :, ::-1]\n",
    "#         print(image)\n",
    "        return image\n",
    "    \n",
    "    def set_alpha(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        return self\n",
    "    \n",
    "    def set_beta(self, beta):\n",
    "        self.beta = beta\n",
    "        return self\n",
    "    \n",
    "    def set_variance_wieght(self, v_weight):\n",
    "        self.v_weight = v_weight\n",
    "        return self\n",
    "    \n",
    "    def set_iters(self, iterations):\n",
    "        self.iterations = iterations\n",
    "        return self\n",
    "    \n",
    "    def load_content(self, image_path):\n",
    "        image = PIL.Image.open(image_path)\n",
    "        self.content = self._process_img(image)\n",
    "        self.base = self._generate_base(self.content)\n",
    "        return self\n",
    "    \n",
    "    def gram_matrix(self, F, N, M):\n",
    "        \"\"\"\n",
    "        The gram matrix G.\n",
    "        F -- the features\n",
    "        N -- number of filters\n",
    "        M -- hight x width of one feature map \n",
    "        Names as per paper\n",
    "        \"\"\"\n",
    "        G = tf.reshape(F, (M, N))\n",
    "        return tf.matmul(tf.transpose(G), G)\n",
    "    \n",
    "    def content_loss(self, sess, graph):\n",
    "        \"\"\"\n",
    "        Compute the context loss as described in the paper. We only need to do the forward \n",
    "        pass once on the content image\n",
    "        \n",
    "        sess -- the current session\n",
    "        content_img -- the content image. should be a numpy array with dimension [1, hight, width, 3]\n",
    "        Note: the dimension of the image should match with the one set at resize_input.\n",
    "        Also, the image should be centered. The mean should be the training set mean of the VGG network.\n",
    "        \"\"\"\n",
    "        graph[\"input\"].assign(self.content).eval()\n",
    "        P = sess.run(graph[self.vgg.content_layer])\n",
    "        F = graph[self.vgg.content_layer]\n",
    "        N = P.shape[3]  # number of filters\n",
    "        M = P.shape[1] * P.shape[2] # hight x width of one feature map \n",
    "        return 0.5 * tf.reduce_sum(tf.pow(F - P, 2))\n",
    "        \n",
    "    \n",
    "    def style_loss(self, sess, graph):\n",
    "        \"\"\"\n",
    "        Compute the style loss as described in the papaer. Again, only do forward pass once for style image\n",
    "        \n",
    "        sess -- the current session\n",
    "        sytle_image -- the style image. Should be a numpy array. 4 dimentions\n",
    "        Note: the style image should also have the same dimension as the content image, either by cropping or \n",
    "        some other methods.\n",
    "        \n",
    "        The style layers will contain multiple layers. Should be a dictionary with keys are the layer name, \n",
    "        and values are the associated weight\n",
    "        \"\"\"\n",
    "        loss = 0.0\n",
    "        style_img = PIL.Image.open(self.style_path) \\\n",
    "                       .resize((self.content.shape[2], self.content.shape[1]), PIL.Image.ANTIALIAS)\n",
    "        style_img = self._process_img(style_img)\n",
    "\n",
    "        graph[\"input\"].assign(style_img).eval()\n",
    "        for key, w in self.vgg.style_layer:\n",
    "            print(key)\n",
    "            P = sess.run(graph[key])\n",
    "            F = graph[key]\n",
    "            N = P.shape[3]  # number of filters\n",
    "            M = P.shape[1] * P.shape[2] # hight x width of one feature map \n",
    "            A = self.gram_matrix(P, N, M)\n",
    "            G = self.gram_matrix(F, N, M)\n",
    "            loss += ((1.0 / (4 * N**2 * M**2)) * tf.reduce_sum(tf.pow(G - A, 2)) * w)\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    def set_optimize_algo(self, algo):\n",
    "        self.opt_algo = algo\n",
    "        return self\n",
    "    \n",
    "    def sum_total_variation_losses(self, graph):\n",
    "        b, h, w, d = self.content.shape\n",
    "        x = graph[\"input\"]\n",
    "        tv_y_size = b * (h-1) * w * d\n",
    "        tv_x_size = b * h * (w-1) * d\n",
    "        loss_y = tf.nn.l2_loss(x[:,1:,:,:] - x[:,:-1,:,:]) \n",
    "        loss_y /= tv_y_size\n",
    "        loss_x = tf.nn.l2_loss(x[:,:,1:,:] - x[:,:,:-1,:]) \n",
    "        loss_x /= tv_x_size\n",
    "        loss = 2 * (loss_y + loss_x)\n",
    "        loss = tf.cast(loss, tf.float32)\n",
    "        return loss\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        The function to finally generate the image\n",
    "        \"\"\"\n",
    "        print(\"shape is\", self.content.shape)\n",
    "        graph, _ = self.vgg.create_graph(self.content.shape)\n",
    "        image = None\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            print(\"initialize variables\")\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            print(\"compute content loss\")\n",
    "            content_loss = self.content_loss(sess, graph) * self.alpha\n",
    "            print(\"compute style loss\")\n",
    "            style_loss   = self.style_loss(sess, graph) * self.beta\n",
    "            print(\"compute total loss\")\n",
    "            tv_loss      = self.sum_total_variation_losses(graph) * self.v_weight\n",
    "            print(\"total variational loss\")\n",
    "            total_loss   = content_loss + style_loss + tv_loss\n",
    "            \n",
    "            train_step   = tf.train.AdamOptimizer(2.0).minimize(total_loss)\n",
    "            \n",
    "            print(\"reinitialize the variables\")\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            graph[\"input\"].assign(self.base).eval()\n",
    "            \n",
    "            if self.opt_algo == \"adam\":\n",
    "                ##### Adam optimization algorithm\n",
    "                print(\"iterative update starts\")\n",
    "                for i in range(self.iterations):\n",
    "                    sess.run(train_step)\n",
    "                    if (i + 1) % 10 == 0:\n",
    "                        print(\".\", end=\" \")\n",
    "                    if (i + 1) % 100 == 0:\n",
    "                        c_loss = content_loss.eval()\n",
    "                        s_loss = style_loss.eval()\n",
    "                        v_loss = tv_loss.eval()\n",
    "                        t_loss = total_loss.eval()\n",
    "                        print()\n",
    "                        print(\"%f, %f, %f, %f\" % (c_loss, s_loss, v_loss, t_loss))\n",
    "            \n",
    "            if self.opt_algo == \"lbfgsb\":\n",
    "            ##### L-BFGS-B optimization algorithm\n",
    "                optimizer = tf.contrib.opt.ScipyOptimizerInterface(total_loss, method='L-BFGS-B',\n",
    "                                                                  options={'maxiter': self.iterations,\n",
    "                                                                              'disp': 50})\n",
    "                optimizer.minimize(sess)\n",
    "            \n",
    "            image = graph[\"input\"].eval()\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "#         image = image[:, :, :, ::-1]\n",
    "        image += MagicPen.IMG_MEAN\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del pen\n",
    "except NameError:\n",
    "    print(\"pen is not defined\")\n",
    "else:\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load graph\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "pen = MagicPen(\"VGG19\", \"models/imagenet-vgg-verydeep-19.mat\", \"starry_night.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape is (1, 384, 512, 3)\n",
      "initialize variables\n",
      "compute content loss\n",
      "compute style loss\n",
      "relu1_1\n",
      "relu2_1\n",
      "relu3_1\n",
      "relu4_1\n",
      "relu5_1\n",
      "compute total loss\n",
      "total variational loss\n",
      "reinitialize the variables\n"
     ]
    }
   ],
   "source": [
    "image = pen.load_content(\"tubingen.png\").set_alpha(0.01).set_beta(20000).set_variance_wieght(1e-3).set_iters(800).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def showarray(a, fmt='jpeg'):\n",
    "    \"\"\"\n",
    "    lol, copied from tf deep dream tutorial\n",
    "    \"\"\"\n",
    "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
    "    f = BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "converted_image = np.clip((image[0]), 0, 255).astype('uint8')\n",
    "showarray(converted_image / 255.0)\n",
    "print(image[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
